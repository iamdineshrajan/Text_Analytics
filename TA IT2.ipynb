{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "t1=\"Now, with the same commandd, we can give @the confidence regionn as well. Now, I am goin*g to set the heiight, whiCh = h here, as 2 and the l!ine type as 2. So, height is at which you want the line to be dra#@wn and line type is nothing but how you want the line to be drawn. So, you canhave dashed lines solid line, dashed and a dot. So, you have several options in there similarly, I also need a lower confidence limit. So, I am setting that to be = - 2 and for the same limit I am setting the line type to be = 2.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=t1.lower()\n",
    "t1=t1.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "t2=\"\".join([char for char in t1 if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "t3=word_tokenize(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "t4=stopwords.words('english')\n",
    "t5=[word for word in t3 if word not in t4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "t6=PorterStemmer()\n",
    "t7=[t6.stem(word) for word in t5]\n",
    "for word in t5:\n",
    "    t6.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "t8=WordNetLemmatizer()\n",
    "t9=[]\n",
    "for word in t5:\n",
    "    t9.append(t8.lemmatize(word))\n",
    "    t8.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "t10=pos_tag(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'line': 6, '2': 4, 'type': 3, 'confidence': 2, 'want': 2, 'drawn': 2, 'dashed': 2, 'limit': 2, 'setting': 2, 'commandd': 1, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t11=FreqDist(t5)\n",
    "t11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      line          2       type confidence       want      drawn     dashed      limit    setting   commandd       give    regionn       well      going        set    heiight          h     height    nothing    canhave      lines      solid        dot    several    options  similarly       also       need      lower \n",
      "         6          4          3          2          2          2          2          2          2          1          1          1          1          1          1          1          1          1          1          1          1          1          1          1          1          1          1          1          1 \n"
     ]
    }
   ],
   "source": [
    "t11.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_data=pd.read_csv(r'C:\\Users\\DELL\\Downloads\\tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   sentiment   100 non-null    object \n",
      " 1   text        100 non-null    object \n",
      " 2   Unnamed: 2  0 non-null      float64\n",
      " 3   Unnamed: 3  1 non-null      object \n",
      " 4   Unnamed: 4  1 non-null      object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=tweet_data[['sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral=tweets[tweets['sentiment']=='neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=tweets[tweets['sentiment']=='positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of positive tweets is (35, 2)\n"
     ]
    }
   ],
   "source": [
    "print('the shape of positive tweets is {}'.format(positive.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of negative tweets is (9, 2)\n"
     ]
    }
   ],
   "source": [
    "negative=tweets[tweets['sentiment']=='negative']\n",
    "print('the shape of negative tweets is {}'.format(negative.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get Premium Tools and content , Upgrade to VIP https://t.co/HatjFbJ4LX\\\\n\\\\n#bigdata \\\\n#ViVAtech2021\\\\n#DEVCommunity‚Ä¶ https://t.co/3DkaMxpekL RT @PinakiLaskar: #datascience job roles. How to make money with your #programming skills\\\\n\\\\n#BigData #Analytics #DataScience #IoT #IIoT #RSt‚Ä¶ RT @throttlefix: botnet fuerte\\\\n https://t.co/hFtuP0LaV9\\\\n\\\\n#bigdata \\\\n#ViVAtech2021\\\\n#DEVCommunity #teChnOlOgy #Programming #AI #iioT #100DaysO‚Ä¶ RT @HaroldSinnott: üò± #MachineLearning App Ideas 2021\\\\n\\\\nvia @ValueCoders\\\\nhttps://t.co/9FngS1ycMQ\\\\n\\\\n#AI #5G #Healthcare #SmartCity #FutureofWor‚Ä¶ RT @PinakiLaskar: STEPS TO KICK OFF YOUR DATA SCIENCE LEARNING PATH\\\\n\\\\n#MachineLearning #BigData #Analytics #DataScience #IoT #IIoT #Python #‚Ä¶ RT @PinakiLaskar: STEPS TO KICK OFF YOUR DATA SCIENCE LEARNING PATH\\\\n\\\\n#MachineLearning #BigData #Analytics #DataScience #IoT #IIoT #Python #‚Ä¶ RT @BotPoetsSociety: Can you guess the #poem that is human and the one created by #MachineLearning ?\\\\n\\\\n #machinelearning #datascience  #Arti‚Ä¶ botnet fuerte\\\\n https://t.co/hFtuP0LaV9\\\\n\\\\n#bigdata \\\\n#ViVAtech2021\\\\n#DEVCommunity #teChnOlOgy #Programming #AI #iioT‚Ä¶ https://t.co/ojzkiIpiwX RT @andi_staub: Challenges in the #AI Industry\\\\n\\\\n#datascience #bigtech #bigdata #fintech #algorithms @ipfconline1 @mvollmer1 @sallyeaves @Mi‚Ä¶ RT @statsenegal: #PrixAgriData : #journalistes, #√©tudiants, #chercheurs, ce concours est pour vous. Faites parler votre cr√©ativit√© avec les‚Ä¶ RT @PinakiLaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#BigData #Analytics #DataScience #IoT #IIoT #RStats #JavaScript #ReactJS #CloudComputing #Serverless #Linux #Progr‚Ä¶ RT @PinakiLaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#BigData #Analytics #DataScience #IoT #IIoT #RStats #JavaScript #ReactJS #CloudComputing #Serverless #Linux #Progr‚Ä¶ RT @andi_staub: Why #MachineLearning is not #ArtificialIntelligence?\\\\n\\\\n#AI #datascience #bigdata #NLP #fintech #robotics @WSWMUC @KMcDTech @‚Ä¶ RT @PinakiLaskar: STEPS TO KICK OFF YOUR DATA SCIENCE LEARNING PATH\\\\n\\\\n#MachineLearning #BigData #Analytics #DataScience #IoT #IIoT #Python #‚Ä¶ RT @PinakiLaskar: STEPS TO KICK OFF YOUR DATA SCIENCE LEARNING PATH\\\\n\\\\n#MachineLearning #BigData #Analytics #DataScience #IoT #IIoT #Python #‚Ä¶ RT @thinksysinc: #Artificialntelligence is changing the world- #Infographic by @antgrasso \\\\n\\\\nCc: @ipfconline1 @MikeQuindazzi @PwC @DeepLearn‚Ä¶ We offer quality assignment help!!\\\\nEnglish\\\\n#Nursing \\\\nMedicine\\\\nBiology\\\\nChemistry\\\\nHistory\\\\nMath\\\\nAccounting Economics\\\\nA‚Ä¶ https://t.co/NJwf6dcvCB RT @PinakiLaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#BigData #Analytics #DataScience #IoT #IIoT #RStats #JavaScript #ReactJS #CloudComputing #Serverless #Linux #Progr‚Ä¶ RT @AlkayalWajdi: How To Create A Typescript Project With Expressjs \\\\n#BigData #Analytics #DataScience #AI #MachineLearning #IoT  #Python #R‚Ä¶ RT @PinakiLaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#BigData #Analytics #DataScience #IoT #IIoT #RStats #JavaScript #ReactJS #CloudComputing #Serverless #Linux #Progr‚Ä¶ RT @machinelearnflx: Data Science Math Skills https://t.co/deSgmk28nN  #machinelearning #datascience #bigdata #ad RT @andi_staub: Why #MachineLearning is not #ArtificialIntelligence?\\\\n\\\\n#AI #datascience #bigdata #NLP #fintech #robotics @WSWMUC @KMcDTech @‚Ä¶ RT @thinksysinc: #Artificialntelligence is changing the world- #Infographic by @antgrasso \\\\n\\\\nCc: @ipfconline1 @MikeQuindazzi @PwC @DeepLearn‚Ä¶ RT @RichardEudes: Why Open Data is Not Enough https://t.co/EW5KZDHxs6 #analytics #datascience, #artificialintelligence, #bigdata, #business‚Ä¶ RT @mandomando: ( Git Cheat Sheet )\\\\n#CodeNewbie #ML #AI #MachineLearning #code #DataScience #rstats #100DaysOfMLCode #javascript #reactjs #‚Ä¶ RT @andi_staub: Why #MachineLearning is not #ArtificialIntelligence?\\\\n\\\\n#AI #datascience #bigdata #NLP #fintech #robotics @WSWMUC @KMcDTech @‚Ä¶ RT @RConsortium: R Consortium members continue to make a place for R in industry - Extending the performance of scalability of R in databas‚Ä¶ RT @UliastiAgency: Deep learning explained. üëáüèº\\\\n\\\\n#DeepLearning #code #Python #javascript #Java #coding #learning #MachineLearning #100DaysOf‚Ä¶ RT @UliastiAgency: Deep learning explained. üëáüèº\\\\n\\\\n#DeepLearning #code #Python #javascript #Java #coding #learning #MachineLearning #100DaysOf‚Ä¶ RT @UliastiAgency: Deep learning explained. üëáüèº\\\\n\\\\n#DeepLearning #code #Python #javascript #Java #coding #learning #MachineLearning #100DaysOf‚Ä¶ RT @HaroldSinnott: 14 #DataScience projects to improve your #skills \\\\n\\\\nvia @kdnuggets\\\\nhttps://t.co/geHVwNEq4q\\\\n\\\\n#KDN #AI #MachineLearning #Io‚Ä¶ RT @IainLJBrown: Why I believe a code of #ethics is needed in the data science community\\\\n\\\\n#ArtificialIntelligence #AI #DataScience #100Days‚Ä¶ RT @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wEzdLG7VBO \\\\n\\\\n#bigdata\\\\n#Women\\\\n#DATASCiENCE #USA \\\\n#CustServ #‚Ä¶ RT @chidambara09: #Khlo√© #Tristan \\\\nbreakup  https://t.co/38BzIf9PIo \\\\n#bigdata\\\\n#Women #WEb\\\\n#DATASCiENCE #USA \\\\n#CustServ #SupplyChain\\\\n#CX #di‚Ä¶ RT @IainLJBrown: Why I believe a code of #ethics is needed in the data science community\\\\n\\\\n#ArtificialIntelligence #AI #DataScience #100Days‚Ä¶ RT @chidambara09: #Khlo√© #Tristan \\\\nbreakup  https://t.co/38BzIf9PIo \\\\n#bigdata\\\\n#Women #WEb\\\\n#DATASCiENCE #USA \\\\n#CustServ #SupplyChain\\\\n#CX #di‚Ä¶ How to Gain Certainty in Uncertain Times with Embedded Analytics \\\\n\\\\n#analytics #data #datascience\\\\nhttps://t.co/R1dFwnSRI1 RT @chidambara09: #Khlo√© #Tristan \\\\nbreakup  https://t.co/38BzIf9PIo \\\\n#bigdata\\\\n#Women #WEb\\\\n#DATASCiENCE #USA \\\\n#CustServ #SupplyChain\\\\n#CX #di‚Ä¶ RT @_ArifChaudhary: üêç Forget 10x engineers, there are 100x and 1000x engineers out there.\\\\n\\\\n#engineer #Engineering #developers \\\\n#programming‚Ä¶ RT @ajay_kolii: Is it acceptable to make a density plot for Likert scale variable? #rstats #stats #DataScience https://t.co/oEAnGBN0Mh RT @_ArifChaudhary: üêç Forget 10x engineers, there are 100x and 1000x engineers out there.\\\\n\\\\n#engineer #Engineering #developers \\\\n#programming‚Ä¶ RT @digitalkecom: #Artificialntelligence is changing the world- #Infographic by @antgrasso \\\\n\\\\nCc: @ipfconline1 @MikeQuindazzi @PwC @DeepLear‚Ä¶ RT @Datascience__: Introduction to Machine Learning with Python: A Guide for Data Scientists https://t.co/i3NmlHEg0r #datascience #ad RT @machinelearnflx: Data Science Math Skills https://t.co/deSgmk28nN  #machinelearning #datascience #bigdata #ad RT @chidambara09: #Khlo√© #Tristan \\\\nbreakup  https://t.co/38BzIf9PIo \\\\n#bigdata\\\\n#Women #WEb\\\\n#DATASCiENCE #USA \\\\n#CustServ #SupplyChain\\\\n#CX #di‚Ä¶ RT @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wEzdLG7VBO \\\\n\\\\n#bigdata\\\\n#Women\\\\n#DATASCiENCE #USA \\\\n#CustServ #‚Ä¶ RT @Datascience__: Introduction to Machine Learning with Python: A Guide for Data Scientists https://t.co/i3NmlHEg0r #datascience #ad RT @machinelearnflx: Machine Learning for Trading https://t.co/AbEcGgRvy0  #machinelearning #datascience #bigdata #ad RT @throttlefix: Get Premium Tools and content , Upgrade to VIP https://t.co/hFtuP0LaV9\\\\n\\\\n#bigdata \\\\n#ViVAtech2021\\\\n#DEVCommunity #teChnOlOgy‚Ä¶ RT @mvollmer1: Cybersecurity Challenges in the Uptake of #ArtificialIntelligence in #AutonomousDriving \\\\n\\\\nhttps://t.co/NLwuLop6lI via @ingli‚Ä¶ RT @throttlefix: Get Premium Tools and content , Upgrade to VIP https://t.co/hFtuP0LaV9\\\\n\\\\n#bigdata \\\\n#ViVAtech2021\\\\n#DEVCommunity #teChnOlOgy‚Ä¶ RT @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wEzdLG7VBO \\\\n\\\\n#bigdata\\\\n#Women\\\\n#DATASCiENCE #USA \\\\n#CustServ #‚Ä¶ RT @throttlefix: Get Premium Tools and content , Upgrade to VIP https://t.co/hFtuP0LaV9\\\\n\\\\n#bigdata \\\\n#ViVAtech2021\\\\n#DEVCommunity #teChnOlOgy‚Ä¶ RT @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wEzdLG7VBO \\\\n\\\\n#bigdata\\\\n#Women\\\\n#DATASCiENCE #USA \\\\n#CustServ #‚Ä¶ RT @Little_Redstone: üìç Scam Alert üìµ theft by ü§èü¶Ñ #Houzz \\\\n#Evilest 1 #Woman ü§°#Business #Canada #Security  #web #Google #Webinar  #BigData #An‚Ä¶ RT @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wEzdLG7VBO \\\\n\\\\n#bigdata\\\\n#Women\\\\n#DATASCiENCE #USA \\\\n#CustServ #‚Ä¶'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_text=' '.join(neutral['text'])\n",
    "neutral_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7928"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neutral_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist=FreqDist(neutral_text)\n",
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_text=neutral_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get premium tools and content , upgrade to vip https://t.co/hatjfbj4lx\\\\n\\\\n#bigdata \\\\n#vivatech2021\\\\n#devcommunity‚Ä¶ https://t.co/3dkamxpekl rt @pinakilaskar: #datascience job roles. how to make money with your #programming skills\\\\n\\\\n#bigdata #analytics #datascience #iot #iiot #rst‚Ä¶ rt @throttlefix: botnet fuerte\\\\n https://t.co/hftup0lav9\\\\n\\\\n#bigdata \\\\n#vivatech2021\\\\n#devcommunity #technology #programming #ai #iiot #100dayso‚Ä¶ rt @haroldsinnott: üò± #machinelearning app ideas 2021\\\\n\\\\nvia @valuecoders\\\\nhttps://t.co/9fngs1ycmq\\\\n\\\\n#ai #5g #healthcare #smartcity #futureofwor‚Ä¶ rt @pinakilaskar: steps to kick off your data science learning path\\\\n\\\\n#machinelearning #bigdata #analytics #datascience #iot #iiot #python #‚Ä¶ rt @pinakilaskar: steps to kick off your data science learning path\\\\n\\\\n#machinelearning #bigdata #analytics #datascience #iot #iiot #python #‚Ä¶ rt @botpoetssociety: can you guess the #poem that is human and the one created by #machinelearning ?\\\\n\\\\n #machinelearning #datascience  #arti‚Ä¶ botnet fuerte\\\\n https://t.co/hftup0lav9\\\\n\\\\n#bigdata \\\\n#vivatech2021\\\\n#devcommunity #technology #programming #ai #iiot‚Ä¶ https://t.co/ojzkiipiwx rt @andi_staub: challenges in the #ai industry\\\\n\\\\n#datascience #bigtech #bigdata #fintech #algorithms @ipfconline1 @mvollmer1 @sallyeaves @mi‚Ä¶ rt @statsenegal: #prixagridata : #journalistes, #√©tudiants, #chercheurs, ce concours est pour vous. faites parler votre cr√©ativit√© avec les‚Ä¶ rt @pinakilaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#bigdata #analytics #datascience #iot #iiot #rstats #javascript #reactjs #cloudcomputing #serverless #linux #progr‚Ä¶ rt @pinakilaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#bigdata #analytics #datascience #iot #iiot #rstats #javascript #reactjs #cloudcomputing #serverless #linux #progr‚Ä¶ rt @andi_staub: why #machinelearning is not #artificialintelligence?\\\\n\\\\n#ai #datascience #bigdata #nlp #fintech #robotics @wswmuc @kmcdtech @‚Ä¶ rt @pinakilaskar: steps to kick off your data science learning path\\\\n\\\\n#machinelearning #bigdata #analytics #datascience #iot #iiot #python #‚Ä¶ rt @pinakilaskar: steps to kick off your data science learning path\\\\n\\\\n#machinelearning #bigdata #analytics #datascience #iot #iiot #python #‚Ä¶ rt @thinksysinc: #artificialntelligence is changing the world- #infographic by @antgrasso \\\\n\\\\ncc: @ipfconline1 @mikequindazzi @pwc @deeplearn‚Ä¶ we offer quality assignment help!!\\\\nenglish\\\\n#nursing \\\\nmedicine\\\\nbiology\\\\nchemistry\\\\nhistory\\\\nmath\\\\naccounting economics\\\\na‚Ä¶ https://t.co/njwf6dcvcb rt @pinakilaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#bigdata #analytics #datascience #iot #iiot #rstats #javascript #reactjs #cloudcomputing #serverless #linux #progr‚Ä¶ rt @alkayalwajdi: how to create a typescript project with expressjs \\\\n#bigdata #analytics #datascience #ai #machinelearning #iot  #python #r‚Ä¶ rt @pinakilaskar: ‚àû‚àû‚àû‚àû‚àû\\\\n\\\\n#bigdata #analytics #datascience #iot #iiot #rstats #javascript #reactjs #cloudcomputing #serverless #linux #progr‚Ä¶ rt @machinelearnflx: data science math skills https://t.co/desgmk28nn  #machinelearning #datascience #bigdata #ad rt @andi_staub: why #machinelearning is not #artificialintelligence?\\\\n\\\\n#ai #datascience #bigdata #nlp #fintech #robotics @wswmuc @kmcdtech @‚Ä¶ rt @thinksysinc: #artificialntelligence is changing the world- #infographic by @antgrasso \\\\n\\\\ncc: @ipfconline1 @mikequindazzi @pwc @deeplearn‚Ä¶ rt @richardeudes: why open data is not enough https://t.co/ew5kzdhxs6 #analytics #datascience, #artificialintelligence, #bigdata, #business‚Ä¶ rt @mandomando: ( git cheat sheet )\\\\n#codenewbie #ml #ai #machinelearning #code #datascience #rstats #100daysofmlcode #javascript #reactjs #‚Ä¶ rt @andi_staub: why #machinelearning is not #artificialintelligence?\\\\n\\\\n#ai #datascience #bigdata #nlp #fintech #robotics @wswmuc @kmcdtech @‚Ä¶ rt @rconsortium: r consortium members continue to make a place for r in industry - extending the performance of scalability of r in databas‚Ä¶ rt @uliastiagency: deep learning explained. üëáüèº\\\\n\\\\n#deeplearning #code #python #javascript #java #coding #learning #machinelearning #100daysof‚Ä¶ rt @uliastiagency: deep learning explained. üëáüèº\\\\n\\\\n#deeplearning #code #python #javascript #java #coding #learning #machinelearning #100daysof‚Ä¶ rt @uliastiagency: deep learning explained. üëáüèº\\\\n\\\\n#deeplearning #code #python #javascript #java #coding #learning #machinelearning #100daysof‚Ä¶ rt @haroldsinnott: 14 #datascience projects to improve your #skills \\\\n\\\\nvia @kdnuggets\\\\nhttps://t.co/gehvwneq4q\\\\n\\\\n#kdn #ai #machinelearning #io‚Ä¶ rt @iainljbrown: why i believe a code of #ethics is needed in the data science community\\\\n\\\\n#artificialintelligence #ai #datascience #100days‚Ä¶ rt @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wezdlg7vbo \\\\n\\\\n#bigdata\\\\n#women\\\\n#datascience #usa \\\\n#custserv #‚Ä¶ rt @chidambara09: #khlo√© #tristan \\\\nbreakup  https://t.co/38bzif9pio \\\\n#bigdata\\\\n#women #web\\\\n#datascience #usa \\\\n#custserv #supplychain\\\\n#cx #di‚Ä¶ rt @iainljbrown: why i believe a code of #ethics is needed in the data science community\\\\n\\\\n#artificialintelligence #ai #datascience #100days‚Ä¶ rt @chidambara09: #khlo√© #tristan \\\\nbreakup  https://t.co/38bzif9pio \\\\n#bigdata\\\\n#women #web\\\\n#datascience #usa \\\\n#custserv #supplychain\\\\n#cx #di‚Ä¶ how to gain certainty in uncertain times with embedded analytics \\\\n\\\\n#analytics #data #datascience\\\\nhttps://t.co/r1dfwnsri1 rt @chidambara09: #khlo√© #tristan \\\\nbreakup  https://t.co/38bzif9pio \\\\n#bigdata\\\\n#women #web\\\\n#datascience #usa \\\\n#custserv #supplychain\\\\n#cx #di‚Ä¶ rt @_arifchaudhary: üêç forget 10x engineers, there are 100x and 1000x engineers out there.\\\\n\\\\n#engineer #engineering #developers \\\\n#programming‚Ä¶ rt @ajay_kolii: is it acceptable to make a density plot for likert scale variable? #rstats #stats #datascience https://t.co/oeangbn0mh rt @_arifchaudhary: üêç forget 10x engineers, there are 100x and 1000x engineers out there.\\\\n\\\\n#engineer #engineering #developers \\\\n#programming‚Ä¶ rt @digitalkecom: #artificialntelligence is changing the world- #infographic by @antgrasso \\\\n\\\\ncc: @ipfconline1 @mikequindazzi @pwc @deeplear‚Ä¶ rt @datascience__: introduction to machine learning with python: a guide for data scientists https://t.co/i3nmlheg0r #datascience #ad rt @machinelearnflx: data science math skills https://t.co/desgmk28nn  #machinelearning #datascience #bigdata #ad rt @chidambara09: #khlo√© #tristan \\\\nbreakup  https://t.co/38bzif9pio \\\\n#bigdata\\\\n#women #web\\\\n#datascience #usa \\\\n#custserv #supplychain\\\\n#cx #di‚Ä¶ rt @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wezdlg7vbo \\\\n\\\\n#bigdata\\\\n#women\\\\n#datascience #usa \\\\n#custserv #‚Ä¶ rt @datascience__: introduction to machine learning with python: a guide for data scientists https://t.co/i3nmlheg0r #datascience #ad rt @machinelearnflx: machine learning for trading https://t.co/abecggrvy0  #machinelearning #datascience #bigdata #ad rt @throttlefix: get premium tools and content , upgrade to vip https://t.co/hftup0lav9\\\\n\\\\n#bigdata \\\\n#vivatech2021\\\\n#devcommunity #technology‚Ä¶ rt @mvollmer1: cybersecurity challenges in the uptake of #artificialintelligence in #autonomousdriving \\\\n\\\\nhttps://t.co/nlwulop6li via @ingli‚Ä¶ rt @throttlefix: get premium tools and content , upgrade to vip https://t.co/hftup0lav9\\\\n\\\\n#bigdata \\\\n#vivatech2021\\\\n#devcommunity #technology‚Ä¶ rt @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wezdlg7vbo \\\\n\\\\n#bigdata\\\\n#women\\\\n#datascience #usa \\\\n#custserv #‚Ä¶ rt @throttlefix: get premium tools and content , upgrade to vip https://t.co/hftup0lav9\\\\n\\\\n#bigdata \\\\n#vivatech2021\\\\n#devcommunity #technology‚Ä¶ rt @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wezdlg7vbo \\\\n\\\\n#bigdata\\\\n#women\\\\n#datascience #usa \\\\n#custserv #‚Ä¶ rt @little_redstone: üìç scam alert üìµ theft by ü§èü¶Ñ #houzz \\\\n#evilest 1 #woman ü§°#business #canada #security  #web #google #webinar  #bigdata #an‚Ä¶ rt @chidambara09: #cyber #fashion #market where #digital clothes \\\\n\\\\nhttps://t.co/wezdlg7vbo \\\\n\\\\n#bigdata\\\\n#women\\\\n#datascience #usa \\\\n#custserv #‚Ä¶'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_text=\"\".join([words for words in neutral_text if words not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get premium tools and content  upgrade to vip httpstcohatjfbj4lxnnbigdata nvivatech2021ndevcommunity‚Ä¶ httpstco3dkamxpekl rt pinakilaskar datascience job roles how to make money with your programming skillsnnbigdata analytics datascience iot iiot rst‚Ä¶ rt throttlefix botnet fuerten httpstcohftup0lav9nnbigdata nvivatech2021ndevcommunity technology programming ai iiot 100dayso‚Ä¶ rt haroldsinnott üò± machinelearning app ideas 2021nnvia valuecodersnhttpstco9fngs1ycmqnnai 5g healthcare smartcity futureofwor‚Ä¶ rt pinakilaskar steps to kick off your data science learning pathnnmachinelearning bigdata analytics datascience iot iiot python ‚Ä¶ rt pinakilaskar steps to kick off your data science learning pathnnmachinelearning bigdata analytics datascience iot iiot python ‚Ä¶ rt botpoetssociety can you guess the poem that is human and the one created by machinelearning nn machinelearning datascience  arti‚Ä¶ botnet fuerten httpstcohftup0lav9nnbigdata nvivatech2021ndevcommunity technology programming ai iiot‚Ä¶ httpstcoojzkiipiwx rt andistaub challenges in the ai industrynndatascience bigtech bigdata fintech algorithms ipfconline1 mvollmer1 sallyeaves mi‚Ä¶ rt statsenegal prixagridata  journalistes √©tudiants chercheurs ce concours est pour vous faites parler votre cr√©ativit√© avec les‚Ä¶ rt pinakilaskar ‚àû‚àû‚àû‚àû‚àûnnbigdata analytics datascience iot iiot rstats javascript reactjs cloudcomputing serverless linux progr‚Ä¶ rt pinakilaskar ‚àû‚àû‚àû‚àû‚àûnnbigdata analytics datascience iot iiot rstats javascript reactjs cloudcomputing serverless linux progr‚Ä¶ rt andistaub why machinelearning is not artificialintelligencennai datascience bigdata nlp fintech robotics wswmuc kmcdtech ‚Ä¶ rt pinakilaskar steps to kick off your data science learning pathnnmachinelearning bigdata analytics datascience iot iiot python ‚Ä¶ rt pinakilaskar steps to kick off your data science learning pathnnmachinelearning bigdata analytics datascience iot iiot python ‚Ä¶ rt thinksysinc artificialntelligence is changing the world infographic by antgrasso nncc ipfconline1 mikequindazzi pwc deeplearn‚Ä¶ we offer quality assignment helpnenglishnnursing nmedicinenbiologynchemistrynhistorynmathnaccounting economicsna‚Ä¶ httpstconjwf6dcvcb rt pinakilaskar ‚àû‚àû‚àû‚àû‚àûnnbigdata analytics datascience iot iiot rstats javascript reactjs cloudcomputing serverless linux progr‚Ä¶ rt alkayalwajdi how to create a typescript project with expressjs nbigdata analytics datascience ai machinelearning iot  python r‚Ä¶ rt pinakilaskar ‚àû‚àû‚àû‚àû‚àûnnbigdata analytics datascience iot iiot rstats javascript reactjs cloudcomputing serverless linux progr‚Ä¶ rt machinelearnflx data science math skills httpstcodesgmk28nn  machinelearning datascience bigdata ad rt andistaub why machinelearning is not artificialintelligencennai datascience bigdata nlp fintech robotics wswmuc kmcdtech ‚Ä¶ rt thinksysinc artificialntelligence is changing the world infographic by antgrasso nncc ipfconline1 mikequindazzi pwc deeplearn‚Ä¶ rt richardeudes why open data is not enough httpstcoew5kzdhxs6 analytics datascience artificialintelligence bigdata business‚Ä¶ rt mandomando  git cheat sheet ncodenewbie ml ai machinelearning code datascience rstats 100daysofmlcode javascript reactjs ‚Ä¶ rt andistaub why machinelearning is not artificialintelligencennai datascience bigdata nlp fintech robotics wswmuc kmcdtech ‚Ä¶ rt rconsortium r consortium members continue to make a place for r in industry  extending the performance of scalability of r in databas‚Ä¶ rt uliastiagency deep learning explained üëáüèºnndeeplearning code python javascript java coding learning machinelearning 100daysof‚Ä¶ rt uliastiagency deep learning explained üëáüèºnndeeplearning code python javascript java coding learning machinelearning 100daysof‚Ä¶ rt uliastiagency deep learning explained üëáüèºnndeeplearning code python javascript java coding learning machinelearning 100daysof‚Ä¶ rt haroldsinnott 14 datascience projects to improve your skills nnvia kdnuggetsnhttpstcogehvwneq4qnnkdn ai machinelearning io‚Ä¶ rt iainljbrown why i believe a code of ethics is needed in the data science communitynnartificialintelligence ai datascience 100days‚Ä¶ rt chidambara09 cyber fashion market where digital clothes nnhttpstcowezdlg7vbo nnbigdatanwomenndatascience usa ncustserv ‚Ä¶ rt chidambara09 khlo√© tristan nbreakup  httpstco38bzif9pio nbigdatanwomen webndatascience usa ncustserv supplychainncx di‚Ä¶ rt iainljbrown why i believe a code of ethics is needed in the data science communitynnartificialintelligence ai datascience 100days‚Ä¶ rt chidambara09 khlo√© tristan nbreakup  httpstco38bzif9pio nbigdatanwomen webndatascience usa ncustserv supplychainncx di‚Ä¶ how to gain certainty in uncertain times with embedded analytics nnanalytics data datasciencenhttpstcor1dfwnsri1 rt chidambara09 khlo√© tristan nbreakup  httpstco38bzif9pio nbigdatanwomen webndatascience usa ncustserv supplychainncx di‚Ä¶ rt arifchaudhary üêç forget 10x engineers there are 100x and 1000x engineers out therennengineer engineering developers nprogramming‚Ä¶ rt ajaykolii is it acceptable to make a density plot for likert scale variable rstats stats datascience httpstcooeangbn0mh rt arifchaudhary üêç forget 10x engineers there are 100x and 1000x engineers out therennengineer engineering developers nprogramming‚Ä¶ rt digitalkecom artificialntelligence is changing the world infographic by antgrasso nncc ipfconline1 mikequindazzi pwc deeplear‚Ä¶ rt datascience introduction to machine learning with python a guide for data scientists httpstcoi3nmlheg0r datascience ad rt machinelearnflx data science math skills httpstcodesgmk28nn  machinelearning datascience bigdata ad rt chidambara09 khlo√© tristan nbreakup  httpstco38bzif9pio nbigdatanwomen webndatascience usa ncustserv supplychainncx di‚Ä¶ rt chidambara09 cyber fashion market where digital clothes nnhttpstcowezdlg7vbo nnbigdatanwomenndatascience usa ncustserv ‚Ä¶ rt datascience introduction to machine learning with python a guide for data scientists httpstcoi3nmlheg0r datascience ad rt machinelearnflx machine learning for trading httpstcoabecggrvy0  machinelearning datascience bigdata ad rt throttlefix get premium tools and content  upgrade to vip httpstcohftup0lav9nnbigdata nvivatech2021ndevcommunity technology‚Ä¶ rt mvollmer1 cybersecurity challenges in the uptake of artificialintelligence in autonomousdriving nnhttpstconlwulop6li via ingli‚Ä¶ rt throttlefix get premium tools and content  upgrade to vip httpstcohftup0lav9nnbigdata nvivatech2021ndevcommunity technology‚Ä¶ rt chidambara09 cyber fashion market where digital clothes nnhttpstcowezdlg7vbo nnbigdatanwomenndatascience usa ncustserv ‚Ä¶ rt throttlefix get premium tools and content  upgrade to vip httpstcohftup0lav9nnbigdata nvivatech2021ndevcommunity technology‚Ä¶ rt chidambara09 cyber fashion market where digital clothes nnhttpstcowezdlg7vbo nnbigdatanwomenndatascience usa ncustserv ‚Ä¶ rt littleredstone üìç scam alert üìµ theft by ü§èü¶Ñ houzz nevilest 1 woman ü§°business canada security  web google webinar  bigdata an‚Ä¶ rt chidambara09 cyber fashion market where digital clothes nnhttpstcowezdlg7vbo nnbigdatanwomenndatascience usa ncustserv ‚Ä¶'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "neutral_text=word_tokenize(neutral_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get',\n",
       " 'premium',\n",
       " 'tools',\n",
       " 'content',\n",
       " 'upgrade',\n",
       " 'vip',\n",
       " 'httpstcohatjfbj4lxnnbigdata',\n",
       " 'nvivatech2021ndevcommunity‚Ä¶',\n",
       " 'httpstco3dkamxpekl',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " 'datascience',\n",
       " 'job',\n",
       " 'roles',\n",
       " 'make',\n",
       " 'money',\n",
       " 'programming',\n",
       " 'skillsnnbigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'rst‚Ä¶',\n",
       " 'rt',\n",
       " 'throttlefix',\n",
       " 'botnet',\n",
       " 'fuerten',\n",
       " 'httpstcohftup0lav9nnbigdata',\n",
       " 'nvivatech2021ndevcommunity',\n",
       " 'technology',\n",
       " 'programming',\n",
       " 'ai',\n",
       " 'iiot',\n",
       " '100dayso‚Ä¶',\n",
       " 'rt',\n",
       " 'haroldsinnott',\n",
       " 'üò±',\n",
       " 'machinelearning',\n",
       " 'app',\n",
       " 'ideas',\n",
       " '2021nnvia',\n",
       " 'valuecodersnhttpstco9fngs1ycmqnnai',\n",
       " '5g',\n",
       " 'healthcare',\n",
       " 'smartcity',\n",
       " 'futureofwor‚Ä¶',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " 'steps',\n",
       " 'kick',\n",
       " 'data',\n",
       " 'science',\n",
       " 'learning',\n",
       " 'pathnnmachinelearning',\n",
       " 'bigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'python',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " 'steps',\n",
       " 'kick',\n",
       " 'data',\n",
       " 'science',\n",
       " 'learning',\n",
       " 'pathnnmachinelearning',\n",
       " 'bigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'python',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'botpoetssociety',\n",
       " 'guess',\n",
       " 'poem',\n",
       " 'human',\n",
       " 'one',\n",
       " 'created',\n",
       " 'machinelearning',\n",
       " 'nn',\n",
       " 'machinelearning',\n",
       " 'datascience',\n",
       " 'arti‚Ä¶',\n",
       " 'botnet',\n",
       " 'fuerten',\n",
       " 'httpstcohftup0lav9nnbigdata',\n",
       " 'nvivatech2021ndevcommunity',\n",
       " 'technology',\n",
       " 'programming',\n",
       " 'ai',\n",
       " 'iiot‚Ä¶',\n",
       " 'httpstcoojzkiipiwx',\n",
       " 'rt',\n",
       " 'andistaub',\n",
       " 'challenges',\n",
       " 'ai',\n",
       " 'industrynndatascience',\n",
       " 'bigtech',\n",
       " 'bigdata',\n",
       " 'fintech',\n",
       " 'algorithms',\n",
       " 'ipfconline1',\n",
       " 'mvollmer1',\n",
       " 'sallyeaves',\n",
       " 'mi‚Ä¶',\n",
       " 'rt',\n",
       " 'statsenegal',\n",
       " 'prixagridata',\n",
       " 'journalistes',\n",
       " '√©tudiants',\n",
       " 'chercheurs',\n",
       " 'ce',\n",
       " 'concours',\n",
       " 'est',\n",
       " 'pour',\n",
       " 'vous',\n",
       " 'faites',\n",
       " 'parler',\n",
       " 'votre',\n",
       " 'cr√©ativit√©',\n",
       " 'avec',\n",
       " 'les‚Ä¶',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " '‚àû‚àû‚àû‚àû‚àûnnbigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'rstats',\n",
       " 'javascript',\n",
       " 'reactjs',\n",
       " 'cloudcomputing',\n",
       " 'serverless',\n",
       " 'linux',\n",
       " 'progr‚Ä¶',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " '‚àû‚àû‚àû‚àû‚àûnnbigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'rstats',\n",
       " 'javascript',\n",
       " 'reactjs',\n",
       " 'cloudcomputing',\n",
       " 'serverless',\n",
       " 'linux',\n",
       " 'progr‚Ä¶',\n",
       " 'rt',\n",
       " 'andistaub',\n",
       " 'machinelearning',\n",
       " 'artificialintelligencennai',\n",
       " 'datascience',\n",
       " 'bigdata',\n",
       " 'nlp',\n",
       " 'fintech',\n",
       " 'robotics',\n",
       " 'wswmuc',\n",
       " 'kmcdtech',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " 'steps',\n",
       " 'kick',\n",
       " 'data',\n",
       " 'science',\n",
       " 'learning',\n",
       " 'pathnnmachinelearning',\n",
       " 'bigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'python',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " 'steps',\n",
       " 'kick',\n",
       " 'data',\n",
       " 'science',\n",
       " 'learning',\n",
       " 'pathnnmachinelearning',\n",
       " 'bigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'python',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'thinksysinc',\n",
       " 'artificialntelligence',\n",
       " 'changing',\n",
       " 'world',\n",
       " 'infographic',\n",
       " 'antgrasso',\n",
       " 'nncc',\n",
       " 'ipfconline1',\n",
       " 'mikequindazzi',\n",
       " 'pwc',\n",
       " 'deeplearn‚Ä¶',\n",
       " 'offer',\n",
       " 'quality',\n",
       " 'assignment',\n",
       " 'helpnenglishnnursing',\n",
       " 'nmedicinenbiologynchemistrynhistorynmathnaccounting',\n",
       " 'economicsna‚Ä¶',\n",
       " 'httpstconjwf6dcvcb',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " '‚àû‚àû‚àû‚àû‚àûnnbigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'rstats',\n",
       " 'javascript',\n",
       " 'reactjs',\n",
       " 'cloudcomputing',\n",
       " 'serverless',\n",
       " 'linux',\n",
       " 'progr‚Ä¶',\n",
       " 'rt',\n",
       " 'alkayalwajdi',\n",
       " 'create',\n",
       " 'typescript',\n",
       " 'project',\n",
       " 'expressjs',\n",
       " 'nbigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'ai',\n",
       " 'machinelearning',\n",
       " 'iot',\n",
       " 'python',\n",
       " 'r‚Ä¶',\n",
       " 'rt',\n",
       " 'pinakilaskar',\n",
       " '‚àû‚àû‚àû‚àû‚àûnnbigdata',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'iot',\n",
       " 'iiot',\n",
       " 'rstats',\n",
       " 'javascript',\n",
       " 'reactjs',\n",
       " 'cloudcomputing',\n",
       " 'serverless',\n",
       " 'linux',\n",
       " 'progr‚Ä¶',\n",
       " 'rt',\n",
       " 'machinelearnflx',\n",
       " 'data',\n",
       " 'science',\n",
       " 'math',\n",
       " 'skills',\n",
       " 'httpstcodesgmk28nn',\n",
       " 'machinelearning',\n",
       " 'datascience',\n",
       " 'bigdata',\n",
       " 'ad',\n",
       " 'rt',\n",
       " 'andistaub',\n",
       " 'machinelearning',\n",
       " 'artificialintelligencennai',\n",
       " 'datascience',\n",
       " 'bigdata',\n",
       " 'nlp',\n",
       " 'fintech',\n",
       " 'robotics',\n",
       " 'wswmuc',\n",
       " 'kmcdtech',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'thinksysinc',\n",
       " 'artificialntelligence',\n",
       " 'changing',\n",
       " 'world',\n",
       " 'infographic',\n",
       " 'antgrasso',\n",
       " 'nncc',\n",
       " 'ipfconline1',\n",
       " 'mikequindazzi',\n",
       " 'pwc',\n",
       " 'deeplearn‚Ä¶',\n",
       " 'rt',\n",
       " 'richardeudes',\n",
       " 'open',\n",
       " 'data',\n",
       " 'enough',\n",
       " 'httpstcoew5kzdhxs6',\n",
       " 'analytics',\n",
       " 'datascience',\n",
       " 'artificialintelligence',\n",
       " 'bigdata',\n",
       " 'business‚Ä¶',\n",
       " 'rt',\n",
       " 'mandomando',\n",
       " 'git',\n",
       " 'cheat',\n",
       " 'sheet',\n",
       " 'ncodenewbie',\n",
       " 'ml',\n",
       " 'ai',\n",
       " 'machinelearning',\n",
       " 'code',\n",
       " 'datascience',\n",
       " 'rstats',\n",
       " '100daysofmlcode',\n",
       " 'javascript',\n",
       " 'reactjs',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'andistaub',\n",
       " 'machinelearning',\n",
       " 'artificialintelligencennai',\n",
       " 'datascience',\n",
       " 'bigdata',\n",
       " 'nlp',\n",
       " 'fintech',\n",
       " 'robotics',\n",
       " 'wswmuc',\n",
       " 'kmcdtech',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'rconsortium',\n",
       " 'r',\n",
       " 'consortium',\n",
       " 'members',\n",
       " 'continue',\n",
       " 'make',\n",
       " 'place',\n",
       " 'r',\n",
       " 'industry',\n",
       " 'extending',\n",
       " 'performance',\n",
       " 'scalability',\n",
       " 'r',\n",
       " 'databas‚Ä¶',\n",
       " 'rt',\n",
       " 'uliastiagency',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'explained',\n",
       " 'üëáüèºnndeeplearning',\n",
       " 'code',\n",
       " 'python',\n",
       " 'javascript',\n",
       " 'java',\n",
       " 'coding',\n",
       " 'learning',\n",
       " 'machinelearning',\n",
       " '100daysof‚Ä¶',\n",
       " 'rt',\n",
       " 'uliastiagency',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'explained',\n",
       " 'üëáüèºnndeeplearning',\n",
       " 'code',\n",
       " 'python',\n",
       " 'javascript',\n",
       " 'java',\n",
       " 'coding',\n",
       " 'learning',\n",
       " 'machinelearning',\n",
       " '100daysof‚Ä¶',\n",
       " 'rt',\n",
       " 'uliastiagency',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'explained',\n",
       " 'üëáüèºnndeeplearning',\n",
       " 'code',\n",
       " 'python',\n",
       " 'javascript',\n",
       " 'java',\n",
       " 'coding',\n",
       " 'learning',\n",
       " 'machinelearning',\n",
       " '100daysof‚Ä¶',\n",
       " 'rt',\n",
       " 'haroldsinnott',\n",
       " '14',\n",
       " 'datascience',\n",
       " 'projects',\n",
       " 'improve',\n",
       " 'skills',\n",
       " 'nnvia',\n",
       " 'kdnuggetsnhttpstcogehvwneq4qnnkdn',\n",
       " 'ai',\n",
       " 'machinelearning',\n",
       " 'io‚Ä¶',\n",
       " 'rt',\n",
       " 'iainljbrown',\n",
       " 'believe',\n",
       " 'code',\n",
       " 'ethics',\n",
       " 'needed',\n",
       " 'data',\n",
       " 'science',\n",
       " 'communitynnartificialintelligence',\n",
       " 'ai',\n",
       " 'datascience',\n",
       " '100days‚Ä¶',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'cyber',\n",
       " 'fashion',\n",
       " 'market',\n",
       " 'digital',\n",
       " 'clothes',\n",
       " 'nnhttpstcowezdlg7vbo',\n",
       " 'nnbigdatanwomenndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'khlo√©',\n",
       " 'tristan',\n",
       " 'nbreakup',\n",
       " 'httpstco38bzif9pio',\n",
       " 'nbigdatanwomen',\n",
       " 'webndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " 'supplychainncx',\n",
       " 'di‚Ä¶',\n",
       " 'rt',\n",
       " 'iainljbrown',\n",
       " 'believe',\n",
       " 'code',\n",
       " 'ethics',\n",
       " 'needed',\n",
       " 'data',\n",
       " 'science',\n",
       " 'communitynnartificialintelligence',\n",
       " 'ai',\n",
       " 'datascience',\n",
       " '100days‚Ä¶',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'khlo√©',\n",
       " 'tristan',\n",
       " 'nbreakup',\n",
       " 'httpstco38bzif9pio',\n",
       " 'nbigdatanwomen',\n",
       " 'webndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " 'supplychainncx',\n",
       " 'di‚Ä¶',\n",
       " 'gain',\n",
       " 'certainty',\n",
       " 'uncertain',\n",
       " 'times',\n",
       " 'embedded',\n",
       " 'analytics',\n",
       " 'nnanalytics',\n",
       " 'data',\n",
       " 'datasciencenhttpstcor1dfwnsri1',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'khlo√©',\n",
       " 'tristan',\n",
       " 'nbreakup',\n",
       " 'httpstco38bzif9pio',\n",
       " 'nbigdatanwomen',\n",
       " 'webndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " 'supplychainncx',\n",
       " 'di‚Ä¶',\n",
       " 'rt',\n",
       " 'arifchaudhary',\n",
       " 'üêç',\n",
       " 'forget',\n",
       " '10x',\n",
       " 'engineers',\n",
       " '100x',\n",
       " '1000x',\n",
       " 'engineers',\n",
       " 'therennengineer',\n",
       " 'engineering',\n",
       " 'developers',\n",
       " 'nprogramming‚Ä¶',\n",
       " 'rt',\n",
       " 'ajaykolii',\n",
       " 'acceptable',\n",
       " 'make',\n",
       " 'density',\n",
       " 'plot',\n",
       " 'likert',\n",
       " 'scale',\n",
       " 'variable',\n",
       " 'rstats',\n",
       " 'stats',\n",
       " 'datascience',\n",
       " 'httpstcooeangbn0mh',\n",
       " 'rt',\n",
       " 'arifchaudhary',\n",
       " 'üêç',\n",
       " 'forget',\n",
       " '10x',\n",
       " 'engineers',\n",
       " '100x',\n",
       " '1000x',\n",
       " 'engineers',\n",
       " 'therennengineer',\n",
       " 'engineering',\n",
       " 'developers',\n",
       " 'nprogramming‚Ä¶',\n",
       " 'rt',\n",
       " 'digitalkecom',\n",
       " 'artificialntelligence',\n",
       " 'changing',\n",
       " 'world',\n",
       " 'infographic',\n",
       " 'antgrasso',\n",
       " 'nncc',\n",
       " 'ipfconline1',\n",
       " 'mikequindazzi',\n",
       " 'pwc',\n",
       " 'deeplear‚Ä¶',\n",
       " 'rt',\n",
       " 'datascience',\n",
       " 'introduction',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'python',\n",
       " 'guide',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'httpstcoi3nmlheg0r',\n",
       " 'datascience',\n",
       " 'ad',\n",
       " 'rt',\n",
       " 'machinelearnflx',\n",
       " 'data',\n",
       " 'science',\n",
       " 'math',\n",
       " 'skills',\n",
       " 'httpstcodesgmk28nn',\n",
       " 'machinelearning',\n",
       " 'datascience',\n",
       " 'bigdata',\n",
       " 'ad',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'khlo√©',\n",
       " 'tristan',\n",
       " 'nbreakup',\n",
       " 'httpstco38bzif9pio',\n",
       " 'nbigdatanwomen',\n",
       " 'webndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " 'supplychainncx',\n",
       " 'di‚Ä¶',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'cyber',\n",
       " 'fashion',\n",
       " 'market',\n",
       " 'digital',\n",
       " 'clothes',\n",
       " 'nnhttpstcowezdlg7vbo',\n",
       " 'nnbigdatanwomenndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'datascience',\n",
       " 'introduction',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'python',\n",
       " 'guide',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'httpstcoi3nmlheg0r',\n",
       " 'datascience',\n",
       " 'ad',\n",
       " 'rt',\n",
       " 'machinelearnflx',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'trading',\n",
       " 'httpstcoabecggrvy0',\n",
       " 'machinelearning',\n",
       " 'datascience',\n",
       " 'bigdata',\n",
       " 'ad',\n",
       " 'rt',\n",
       " 'throttlefix',\n",
       " 'get',\n",
       " 'premium',\n",
       " 'tools',\n",
       " 'content',\n",
       " 'upgrade',\n",
       " 'vip',\n",
       " 'httpstcohftup0lav9nnbigdata',\n",
       " 'nvivatech2021ndevcommunity',\n",
       " 'technology‚Ä¶',\n",
       " 'rt',\n",
       " 'mvollmer1',\n",
       " 'cybersecurity',\n",
       " 'challenges',\n",
       " 'uptake',\n",
       " 'artificialintelligence',\n",
       " 'autonomousdriving',\n",
       " 'nnhttpstconlwulop6li',\n",
       " 'via',\n",
       " 'ingli‚Ä¶',\n",
       " 'rt',\n",
       " 'throttlefix',\n",
       " 'get',\n",
       " 'premium',\n",
       " 'tools',\n",
       " 'content',\n",
       " 'upgrade',\n",
       " 'vip',\n",
       " 'httpstcohftup0lav9nnbigdata',\n",
       " 'nvivatech2021ndevcommunity',\n",
       " 'technology‚Ä¶',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'cyber',\n",
       " 'fashion',\n",
       " 'market',\n",
       " 'digital',\n",
       " 'clothes',\n",
       " 'nnhttpstcowezdlg7vbo',\n",
       " 'nnbigdatanwomenndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'throttlefix',\n",
       " 'get',\n",
       " 'premium',\n",
       " 'tools',\n",
       " 'content',\n",
       " 'upgrade',\n",
       " 'vip',\n",
       " 'httpstcohftup0lav9nnbigdata',\n",
       " 'nvivatech2021ndevcommunity',\n",
       " 'technology‚Ä¶',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'cyber',\n",
       " 'fashion',\n",
       " 'market',\n",
       " 'digital',\n",
       " 'clothes',\n",
       " 'nnhttpstcowezdlg7vbo',\n",
       " 'nnbigdatanwomenndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " 'littleredstone',\n",
       " 'üìç',\n",
       " 'scam',\n",
       " 'alert',\n",
       " 'üìµ',\n",
       " 'theft',\n",
       " 'ü§èü¶Ñ',\n",
       " 'houzz',\n",
       " 'nevilest',\n",
       " '1',\n",
       " 'woman',\n",
       " 'ü§°business',\n",
       " 'canada',\n",
       " 'security',\n",
       " 'web',\n",
       " 'google',\n",
       " 'webinar',\n",
       " 'bigdata',\n",
       " 'an‚Ä¶',\n",
       " 'rt',\n",
       " 'chidambara09',\n",
       " 'cyber',\n",
       " 'fashion',\n",
       " 'market',\n",
       " 'digital',\n",
       " 'clothes',\n",
       " 'nnhttpstcowezdlg7vbo',\n",
       " 'nnbigdatanwomenndatascience',\n",
       " 'usa',\n",
       " 'ncustserv',\n",
       " '‚Ä¶']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_text=[words for words in neutral_text if words not in stopwords.words('english')]\n",
    "neutral_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-1d7cf4cffd6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwordcloud\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneutral_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \"\"\"\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \"\"\"\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m         \u001b[1;31m# remove 's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         words = [word[:-2] if word.lower().endswith(\"'s\") else word\n",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "wordcloud=WordCloud(width=1000,height=500,stopwords=stopwords).generate(neutral_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=collections.Counter(neutral_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=counter.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, 0 was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-f1b892f84ea6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcounter_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;31m# no obvious \"empty\" int column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mensure_index\u001b[1;34m(index_like, copy)\u001b[0m\n\u001b[0;32m   5915\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5917\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DR\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__array__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, 0 was passed"
     ]
    }
   ],
   "source": [
    "counter_df=pd.DataFrame(counter,columns=['words','count'],index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'get': 4,\n",
       "         'premium': 4,\n",
       "         'tools': 4,\n",
       "         'content': 4,\n",
       "         'upgrade': 4,\n",
       "         'vip': 4,\n",
       "         'httpstcohatjfbj4lxnnbigdata': 1,\n",
       "         'nvivatech2021ndevcommunity‚Ä¶': 1,\n",
       "         'httpstco3dkamxpekl': 1,\n",
       "         'rt': 52,\n",
       "         'pinakilaskar': 9,\n",
       "         'datascience': 28,\n",
       "         'job': 1,\n",
       "         'roles': 1,\n",
       "         'make': 3,\n",
       "         'money': 1,\n",
       "         'programming': 3,\n",
       "         'skillsnnbigdata': 1,\n",
       "         'analytics': 12,\n",
       "         'iot': 10,\n",
       "         'iiot': 10,\n",
       "         'rst‚Ä¶': 1,\n",
       "         'throttlefix': 4,\n",
       "         'botnet': 2,\n",
       "         'fuerten': 2,\n",
       "         'httpstcohftup0lav9nnbigdata': 5,\n",
       "         'nvivatech2021ndevcommunity': 5,\n",
       "         'technology': 2,\n",
       "         'ai': 8,\n",
       "         '100dayso‚Ä¶': 1,\n",
       "         'haroldsinnott': 2,\n",
       "         'üò±': 1,\n",
       "         'machinelearning': 15,\n",
       "         'app': 1,\n",
       "         'ideas': 1,\n",
       "         '2021nnvia': 1,\n",
       "         'valuecodersnhttpstco9fngs1ycmqnnai': 1,\n",
       "         '5g': 1,\n",
       "         'healthcare': 1,\n",
       "         'smartcity': 1,\n",
       "         'futureofwor‚Ä¶': 1,\n",
       "         'steps': 4,\n",
       "         'kick': 4,\n",
       "         'data': 12,\n",
       "         'science': 8,\n",
       "         'learning': 13,\n",
       "         'pathnnmachinelearning': 4,\n",
       "         'bigdata': 13,\n",
       "         'python': 10,\n",
       "         '‚Ä¶': 13,\n",
       "         'botpoetssociety': 1,\n",
       "         'guess': 1,\n",
       "         'poem': 1,\n",
       "         'human': 1,\n",
       "         'one': 1,\n",
       "         'created': 1,\n",
       "         'nn': 1,\n",
       "         'arti‚Ä¶': 1,\n",
       "         'iiot‚Ä¶': 1,\n",
       "         'httpstcoojzkiipiwx': 1,\n",
       "         'andistaub': 4,\n",
       "         'challenges': 2,\n",
       "         'industrynndatascience': 1,\n",
       "         'bigtech': 1,\n",
       "         'fintech': 4,\n",
       "         'algorithms': 1,\n",
       "         'ipfconline1': 4,\n",
       "         'mvollmer1': 2,\n",
       "         'sallyeaves': 1,\n",
       "         'mi‚Ä¶': 1,\n",
       "         'statsenegal': 1,\n",
       "         'prixagridata': 1,\n",
       "         'journalistes': 1,\n",
       "         '√©tudiants': 1,\n",
       "         'chercheurs': 1,\n",
       "         'ce': 1,\n",
       "         'concours': 1,\n",
       "         'est': 1,\n",
       "         'pour': 1,\n",
       "         'vous': 1,\n",
       "         'faites': 1,\n",
       "         'parler': 1,\n",
       "         'votre': 1,\n",
       "         'cr√©ativit√©': 1,\n",
       "         'avec': 1,\n",
       "         'les‚Ä¶': 1,\n",
       "         '‚àû‚àû‚àû‚àû‚àûnnbigdata': 4,\n",
       "         'rstats': 6,\n",
       "         'javascript': 8,\n",
       "         'reactjs': 5,\n",
       "         'cloudcomputing': 4,\n",
       "         'serverless': 4,\n",
       "         'linux': 4,\n",
       "         'progr‚Ä¶': 4,\n",
       "         'artificialintelligencennai': 3,\n",
       "         'nlp': 3,\n",
       "         'robotics': 3,\n",
       "         'wswmuc': 3,\n",
       "         'kmcdtech': 3,\n",
       "         'thinksysinc': 2,\n",
       "         'artificialntelligence': 3,\n",
       "         'changing': 3,\n",
       "         'world': 3,\n",
       "         'infographic': 3,\n",
       "         'antgrasso': 3,\n",
       "         'nncc': 3,\n",
       "         'mikequindazzi': 3,\n",
       "         'pwc': 3,\n",
       "         'deeplearn‚Ä¶': 2,\n",
       "         'offer': 1,\n",
       "         'quality': 1,\n",
       "         'assignment': 1,\n",
       "         'helpnenglishnnursing': 1,\n",
       "         'nmedicinenbiologynchemistrynhistorynmathnaccounting': 1,\n",
       "         'economicsna‚Ä¶': 1,\n",
       "         'httpstconjwf6dcvcb': 1,\n",
       "         'alkayalwajdi': 1,\n",
       "         'create': 1,\n",
       "         'typescript': 1,\n",
       "         'project': 1,\n",
       "         'expressjs': 1,\n",
       "         'nbigdata': 1,\n",
       "         'r‚Ä¶': 1,\n",
       "         'machinelearnflx': 3,\n",
       "         'math': 2,\n",
       "         'skills': 3,\n",
       "         'httpstcodesgmk28nn': 2,\n",
       "         'ad': 5,\n",
       "         'richardeudes': 1,\n",
       "         'open': 1,\n",
       "         'enough': 1,\n",
       "         'httpstcoew5kzdhxs6': 1,\n",
       "         'artificialintelligence': 2,\n",
       "         'business‚Ä¶': 1,\n",
       "         'mandomando': 1,\n",
       "         'git': 1,\n",
       "         'cheat': 1,\n",
       "         'sheet': 1,\n",
       "         'ncodenewbie': 1,\n",
       "         'ml': 1,\n",
       "         'code': 6,\n",
       "         '100daysofmlcode': 1,\n",
       "         'rconsortium': 1,\n",
       "         'r': 3,\n",
       "         'consortium': 1,\n",
       "         'members': 1,\n",
       "         'continue': 1,\n",
       "         'place': 1,\n",
       "         'industry': 1,\n",
       "         'extending': 1,\n",
       "         'performance': 1,\n",
       "         'scalability': 1,\n",
       "         'databas‚Ä¶': 1,\n",
       "         'uliastiagency': 3,\n",
       "         'deep': 3,\n",
       "         'explained': 3,\n",
       "         'üëáüèºnndeeplearning': 3,\n",
       "         'java': 3,\n",
       "         'coding': 3,\n",
       "         '100daysof‚Ä¶': 3,\n",
       "         '14': 1,\n",
       "         'projects': 1,\n",
       "         'improve': 1,\n",
       "         'nnvia': 1,\n",
       "         'kdnuggetsnhttpstcogehvwneq4qnnkdn': 1,\n",
       "         'io‚Ä¶': 1,\n",
       "         'iainljbrown': 2,\n",
       "         'believe': 2,\n",
       "         'ethics': 2,\n",
       "         'needed': 2,\n",
       "         'communitynnartificialintelligence': 2,\n",
       "         '100days‚Ä¶': 2,\n",
       "         'chidambara09': 9,\n",
       "         'cyber': 5,\n",
       "         'fashion': 5,\n",
       "         'market': 5,\n",
       "         'digital': 5,\n",
       "         'clothes': 5,\n",
       "         'nnhttpstcowezdlg7vbo': 5,\n",
       "         'nnbigdatanwomenndatascience': 5,\n",
       "         'usa': 9,\n",
       "         'ncustserv': 9,\n",
       "         'khlo√©': 4,\n",
       "         'tristan': 4,\n",
       "         'nbreakup': 4,\n",
       "         'httpstco38bzif9pio': 4,\n",
       "         'nbigdatanwomen': 4,\n",
       "         'webndatascience': 4,\n",
       "         'supplychainncx': 4,\n",
       "         'di‚Ä¶': 4,\n",
       "         'gain': 1,\n",
       "         'certainty': 1,\n",
       "         'uncertain': 1,\n",
       "         'times': 1,\n",
       "         'embedded': 1,\n",
       "         'nnanalytics': 1,\n",
       "         'datasciencenhttpstcor1dfwnsri1': 1,\n",
       "         'arifchaudhary': 2,\n",
       "         'üêç': 2,\n",
       "         'forget': 2,\n",
       "         '10x': 2,\n",
       "         'engineers': 4,\n",
       "         '100x': 2,\n",
       "         '1000x': 2,\n",
       "         'therennengineer': 2,\n",
       "         'engineering': 2,\n",
       "         'developers': 2,\n",
       "         'nprogramming‚Ä¶': 2,\n",
       "         'ajaykolii': 1,\n",
       "         'acceptable': 1,\n",
       "         'density': 1,\n",
       "         'plot': 1,\n",
       "         'likert': 1,\n",
       "         'scale': 1,\n",
       "         'variable': 1,\n",
       "         'stats': 1,\n",
       "         'httpstcooeangbn0mh': 1,\n",
       "         'digitalkecom': 1,\n",
       "         'deeplear‚Ä¶': 1,\n",
       "         'introduction': 2,\n",
       "         'machine': 3,\n",
       "         'guide': 2,\n",
       "         'scientists': 2,\n",
       "         'httpstcoi3nmlheg0r': 2,\n",
       "         'trading': 1,\n",
       "         'httpstcoabecggrvy0': 1,\n",
       "         'technology‚Ä¶': 3,\n",
       "         'cybersecurity': 1,\n",
       "         'uptake': 1,\n",
       "         'autonomousdriving': 1,\n",
       "         'nnhttpstconlwulop6li': 1,\n",
       "         'via': 1,\n",
       "         'ingli‚Ä¶': 1,\n",
       "         'littleredstone': 1,\n",
       "         'üìç': 1,\n",
       "         'scam': 1,\n",
       "         'alert': 1,\n",
       "         'üìµ': 1,\n",
       "         'theft': 1,\n",
       "         'ü§èü¶Ñ': 1,\n",
       "         'houzz': 1,\n",
       "         'nevilest': 1,\n",
       "         '1': 1,\n",
       "         'woman': 1,\n",
       "         'ü§°business': 1,\n",
       "         'canada': 1,\n",
       "         'security': 1,\n",
       "         'web': 1,\n",
       "         'google': 1,\n",
       "         'webinar': 1,\n",
       "         'an‚Ä¶': 1})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
